{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Union\n",
        "from requests import get, Response\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "PATH = 'pars_autoru.csv'\n",
        "URL = 'https://auto.ru/moskva/cars/all/'\n",
        "COOKIE = os.getenv('COOKIE')\n",
        "\n",
        "HEADERS = {\n",
        "    'user-agent': os.getenv('USER_AGENT'),\n",
        "    'accept': os.getenv('ACCEPT'),\n",
        "    'Accept-Language': 'ru',\n",
        "    'accept-encoding': 'accept - encoding: gzip, deflate, br',\n",
        "    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"101\", \"Opera\";v=\"87\"',\n",
        "    'sec-ch-ua-mobile': '?0',\n",
        "    'sec-ch-ua-platform': '\"Windows\"',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "    'Cookie': \"autoru_gdpr=1; suid=c884a3c0767127496a9ebc040a3a4ce9.6209fa50b6d2a9f56642f5b08f671160; \"\n",
        "    \"_csrf_token=305b66f4692deac7ed0d8eb3a0c26df1a090df3ec74c96e4; \"\n",
        "    \"autoru_sid=a%3Ag67c743692nqnqv4215hm4sr696vs7tu.6aa14550ccf50cd8ffe2c9b8163928a6%7C1741112169778.604800.6r1e81CbwDLv69kIupjuzQ.7A7p2P3brGQVeTblXl1x45djo-ugX05hjMzAHXLRLOI; \"\n",
        "    \"autoruuid=g67c743692nqnqv4215hm4sr696vs7tu.6aa14550ccf50cd8ffe2c9b8163928a6; \"\n",
        "    \"from=direct; yandex_login=; \"\n",
        "    \"i=pzRIaqugGPXgRZNJ3jTpx0/XDTMmcXLQ9rqlgyVr07BEfWc8jzmzrSeXolAfpiiL5CalUuqhBz7MiIuoqNYFNl6Mpvo=; \"\n",
        "    \"yandexuid=8285180061601070617; yaPassportTryAutologin=1; \"\n",
        "    \"fp=918bb73e5ab734d215b9a218709c44ea%7C1741112175597; los=1; bltsr=1; coockoos=4; \"\n",
        "    \"autoru_crashreport={%22route_name%22:%22listing%22%2C%22app_id%22:%22af-desktop-search%22}; \"\n",
        "    \"crookie=lQAiCFaRQWBQurFwn6+5Jplf49oSvljI347V717Lizen8S4eZDKwi0e7TOpeHr9U92lDlTBTEvA3kNOO5yrn4AJgufQ=; \"\n",
        "    \"cmtchd=MTc0MTExMjE4NTUyOQ==; popups-popup-car-history-for-free-shown-count=1; \"\n",
        "    \"_ym_uid=1741112385974008306; _ym_isad=1; autoru_sso_blocked=1; \"\n",
        "    \"_yasc=xD63l+RCawFl+2QRavF0Px6uh7ojGMKTtpJHILvy9B9akIgwIS68TsKOCtBgWNrHpw==; \"\n",
        "    \"Session_id=noauth:1741155427; \"\n",
        "    \"sessar=1.1199.CiDzZFUz1wzj8l991kPjWjFazSTD71XT77JDgrBKmhedsw.NeKhNzfFC_9RwhMQNryyOWBVB54hCf_K7sr1uoWwJrI; \"\n",
        "    \"ys=c_chck.329368023; mda2_beacon=1741155427892; sso_status=sso.passport.yandex.ru:synchronized; \"\n",
        "    \"autoru_sso_redirect_blocked=1; _ym_d=1741155434; count-visits=1; \"\n",
        "    \"from_lifetime=1741155438392; \"\n",
        "    'layout-config={\"screen_height\":900,\"screen_width\":1440,\"win_width\":885,\"win_height\":812}'\n",
        "}\n",
        "\n",
        "def get_pages_amount(content: bytes) -> int:\n",
        "    soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "    pagination_block = soup.find(\n",
        "        'span',\n",
        "        class_='ControlGroup ControlGroup_responsive_no ControlGroup_size_s ListingPagination__pages'\n",
        "    )\n",
        "    if not pagination_block:\n",
        "        print(\"Внимание: блок пагинации не найден. Будем считать, что страница одна.\")\n",
        "        return 1\n",
        "\n",
        "    pages = pagination_block.contents\n",
        "    return len(pages)\n",
        "\n",
        "\n",
        "def get_content(html: bytes) -> List[dict]:\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    items = soup.find_all('div', class_='ListingItem')\n",
        "    if not items:\n",
        "        items = soup.find_all('div', class_='ListingItem__description')\n",
        "\n",
        "    cars = []\n",
        "    for item in items:\n",
        "        summary_block = item.find('div', class_='ListingItem__summary')\n",
        "        link_block = item.find('a', class_='ListingItemTitle__link')\n",
        "        price_block = item.find('div', class_='ListingItemPrice__content')\n",
        "        year_block = item.find('div', class_='ListingItem__yearBlock')\n",
        "        summary_text = summary_block.get_text(strip=True) if summary_block else 'N/A'\n",
        "        link = link_block.get('href') if link_block else 'N/A'\n",
        "\n",
        "        if price_block:\n",
        "            price_text = price_block.get_text(strip=True).replace('\\xa0', '').replace('₽', '')\n",
        "        else:\n",
        "            price_text = 'N/A'\n",
        "\n",
        "        year_text = year_block.get_text(strip=True) if year_block else 'N/A'\n",
        "\n",
        "        car = {\n",
        "            'car': summary_text,\n",
        "            'url': link,\n",
        "            'price': price_text,\n",
        "            'year': year_text,\n",
        "        }\n",
        "        cars.append(car)\n",
        "    return cars\n",
        "\n",
        "\n",
        "def get_html(url: str, headers: dict, params: Union[None, dict] = None) -> Response:\n",
        "\n",
        "    try:\n",
        "        return get(url, headers=headers, params=params)\n",
        "    except Exception as error:\n",
        "        raise ConnectionError(f'При выполнении запроса произошла ошибка: {error}')\n",
        "\n",
        "\n",
        "def parse(url: str) -> List[dict]:\n",
        "    url = url or URL\n",
        "    html = get_html(url, HEADERS)\n",
        "\n",
        "    if html.status_code != 200:\n",
        "        print(f\"Сайт вернул статус-код {html.status_code}\")\n",
        "        return []\n",
        "\n",
        "    pages_amount = get_pages_amount(html.content)\n",
        "\n",
        "    cars = []\n",
        "    for i in range(1, pages_amount + 1):\n",
        "        print(f'Парсим {i} страницу из {pages_amount}...')\n",
        "        html = get_html(url, HEADERS, params={'page': i})\n",
        "        if html.status_code != 200:\n",
        "            print(f\"Страница {i} вернула статус-код {html.status_code}, пропускаем.\")\n",
        "            continue\n",
        "\n",
        "        page_cars = get_content(html.content)\n",
        "        cars.extend(page_cars)\n",
        "\n",
        "    print(f'Получены данные по {len(cars)} авто.')\n",
        "\n",
        "    def parse_year(car):\n",
        "        try:\n",
        "            return int(car['year'])\n",
        "        except:\n",
        "            return 0\n",
        "    sorted_cars = sorted(cars, key=parse_year, reverse=True)\n",
        "    return sorted_cars\n",
        "\n",
        "\n",
        "def save_to_file(data) -> None:\n",
        "\n",
        "    with open(PATH, 'w', newline='', encoding='utf-8') as file:\n",
        "        w = csv.writer(file, delimiter=';')\n",
        "        w.writerow(['Car', 'Link', 'Price (RUR)', 'Year'])\n",
        "        for car in data:\n",
        "            w.writerow([\n",
        "                car['car'],\n",
        "                car['url'],\n",
        "                car['price'],\n",
        "                car['year']\n",
        "            ])\n",
        "\n",
        "\n",
        "def main():\n",
        "    url_input = input('URL: ').strip()\n",
        "    data = parse(url_input)\n",
        "    if data:\n",
        "        save_to_file(data)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McrSuwDK8xup",
        "outputId": "dc429dba-1965-4b61-a161-8feffd361e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "URL: \n",
            "Парсим 1 страницу из 11...\n",
            "Парсим 2 страницу из 11...\n",
            "Парсим 3 страницу из 11...\n",
            "Парсим 4 страницу из 11...\n",
            "Парсим 5 страницу из 11...\n",
            "Парсим 6 страницу из 11...\n",
            "Парсим 7 страницу из 11...\n",
            "Парсим 8 страницу из 11...\n",
            "Парсим 9 страницу из 11...\n",
            "Парсим 10 страницу из 11...\n",
            "Парсим 11 страницу из 11...\n",
            "Получены данные по 407 авто.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0K9-YwZ3oiDM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}